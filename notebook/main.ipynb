{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ca1307-f807-4542-a1b4-ce9715989146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "\n",
      "<TRAIN | FOLD 0>\n",
      "(EPOCH 0)\n",
      "  0%|                                                 | 0/29147 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/FakeNewsDetection/KoBERT_Model/notebook/../train_dynamic_quant.py\", line 219, in <module>\n",
      "    train(train_dataset = train_dataset,\n",
      "  File \"/workspace/FakeNewsDetection/KoBERT_Model/notebook/../train_dynamic_quant.py\", line 178, in train\n",
      "    train_loss, train_acc = train_func(model, train_dl, optim, loss_fn, scheduler)\n",
      "  File \"/workspace/FakeNewsDetection/KoBERT_Model/notebook/../train_dynamic_quant.py\", line 126, in train_func\n",
      "    outputs = model(input_ids = input_ids, attention_mask = attention_mask).to(device)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/workspace/FakeNewsDetection/KoBERT_Model/notebook/../train_dynamic_quant.py\", line 76, in forward\n",
      "    hidden_state = self.bert(input_ids = input_ids,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 1006, in forward\n",
      "    embedding_output = self.embeddings(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py\", line 232, in forward\n",
      "    inputs_embeds = self.word_embeddings(input_ids)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 162, in forward\n",
      "    return F.embedding(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py\", line 2233, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "!python ../train_dynamic_quant.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
